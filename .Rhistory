add2 <- function(x,y) {
add2 <- function (x,y) {
x + y
}
add2(3,5)
above <- function (x,n) {
use <- x>n
x[use]
}
x <-1:20
above(x)
above (x,12)
above10 <- function(x,n=10) {
use <- x>10
x[use]
}
above(x)
above10 <- function(x,n=10) {
use <- x>n
x[use]
}
above(x)
above <- function(x,n=10) {
use <- x>n
x[use]
}
above(s)
above(x)
columnmean <-function (y){
nc <- ncol(y)
means <- numeric(nc)
for(i in 1:nc)  {
means[i] <-mean (y[,i])
}
means
}
columnmean(airquality)
columnmean <-function (y, removeNA = TRUE){
nc <- ncol(y)
means <- numeric(nc)
for(i in 1:nc)  {
means[i] <-mean (y[,i], na.rm = removeNA)
}
means
}
columnmean(airquality)
columnmean(airquality. FALSE)
columnmean(airquality,FALSE)
make.power <- function (n) {
pow <- function (x) {
x^n
}
pow
}
cube (3)
cube <- make.power(3)
square <- make.power (2)
cube(3)
square (3)
is (environment (square))
is (environment (cube))
make.power <- function (n) {
+         pow <- function (x) {
+                 x^n
+         }
+         pow
+ }
make.power <- function (n) {
pow <- function (x) {
x^n
}
pow
}
ls(environment(cube))
get("n", environment(cube))
y <- 10
f <- function (x) {
y <- 2
y^2 + g(x)
}
g <- function(x) {
x*y
}
f(3)
f(11)
g <- function (x) {
a <- 3
x+a+y
}
g(2)
y <- 3
g(2)
x <- matrix (1:4,2,2); y <- matrix (rep(10,4),2,2)
x*y
x/y
x %*% y
x <- as.Date ("1970 - 01-01")
x <- as.Date ("1970-01-01")
x
unclass(x)
specdata <- directory
write.arff()
write.arff()
capital <-load("social capital_machine")
capital <-load("social capital_machine.csv")
install.packages("xtab")
install.packages("xtabs")
library(xtabs)
names(which(table(group1$self1) == max(table(group1$self1)))
a
names(which(table(group1$self1) == max(table(group1$self1))))
group1 <- subset(result, groups == 1)
group2 <- subset(result, groups == 2)
#hiearchical
uk.hclust = hclust(uk.dist)
plot(uk.hclust,main='Default from hclust')
capdendro <- as.dendrogram(uk.hclust)
dend1 <- color_branches(capdendro, k = 2)
dendextend::color_branches(k = 2)
plot(capdendro)
#getting the result
groups = cutree(uk.hclust, 2)
result = cbind(uk_clean, groups)
world = read.csv("world.csv", header = TRUE)
library("reshape", lib.loc="~/Library/R/3.2/library")
library("reshape2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
t <- read.table("t.tdv.txt",sep="\t",quote="", fill=TRUE)
ca <- read.table("cat.tdv.txt",sep="\t",quote="", fill=TRUE)
colnames(t)<- c('term','id1','id2','id3','id4','id5')
colnames(ca)<- c('id','cat')
t2 <- melt(t, id=c("term"))
## just to show you what's happened, we can look at all the 'a' terms and see there is now 5 rows for term 'a' with 2 of them containing category numbers in the 'value' column, and 3 of them being 'NA'
t2[t2$term=="a",]
## so now we'll get rid of all the NA values
t2<-t2[complete.cases(t2),]
## for ultra simplicity, we'll remove the unecessary column in t2, and we'll rename the value column so it matches the id column in 'ca'
t3<-data.frame(term=t2$term,id=t2$value)
## now merge should work
m<-merge(ca,t3)
## we can look at m:
head(m)
## or even better, :
m[m$term=='around',]
t <- read.table("t.tdv.txt",sep="\t",quote="", fill=TRUE)
ca <- read.table("cat.tdv.txt",sep="\t",quote="", fill=TRUE)
colnames(t)<- c('term','id1','id2','id3','id4','id5')
colnames(ca)<- c('id','cat')
library(reshape)
t2 <- melt(t, id=c("term"))
## just to show you what's happened, we can look at all the 'a' terms and see there is now 5 rows for term 'a' with 2 of them containing category numbers in the 'value' column, and 3 of them being 'NA'
t2[t2$term=="a",]
## so now we'll get rid of all the NA values
t2<-t2[complete.cases(t2),]
## for ultra simplicity, we'll remove the unecessary column in t2, and we'll rename the value column so it matches the id column in 'ca'
t3<-data.frame(term=t2$term,id=t2$value)
## now merge should work
m<-merge(ca,t3)
## we can look at m:
head(m)
## or even better, :
m[m$term=='around',]
t <- read.table("t.tdv.txt",sep="\t",quote="", fill=TRUE)
ca <- read.table("cat.tdv.txt",sep="\t",quote="", fill=TRUE)
colnames(t)<- c('term','id1','id2','id3','id4','id5')
colnames(ca)<- c('id','cat')
t <- read.table("t.tdv.txt",sep="\t",quote="", fill=TRUE)
ca <- read.table("cat.tdv.txt",sep="\t",quote="", fill=TRUE)
colnames(t)<- c('term','id1','id2','id3','id4','id5')
colnames(ca)<- c('id','cat')
install.packages('reshape')
smi$sall <- smi$smile1+smi$smile2
library(party)
#model 5
tree <- read.csv("tree.csv", header = TRUE)
tree[3:66]<- data.frame(lapply(tree[3:66], function(X) X/X[3325]))
tree = tree[-3325,]
t4 <- tree
t4[,3:66]<-scale(t4[,3:66])
t5 <- t4
t5$b[t5$swl >= 1 & t5$swl < 4.2 ] <- "one"
t5$b[t5$swl >=  2.8 & t5$swl < 4.2 ] <- "two"
t5$b[t5$swl >= 4.2  & t5$swl <= 7] <- "three"
smi <- read.csv("smileys2.csv", header = TRUE)
share_words_top <- c("hate","miss","fuck")
assoc_hate <- findAssocs(enDTM, share_words_top, 0.20)
require(magrittr)
require(tm)
assoc_hate <- findAssocs(enDTM, share_words_top, 0.20)
status <- read.csv("small.csv", header = FALSE, fill=TRUE,row.names=NULL)
#readLines("smallrandomsample.csv", warn=FALSE)
#clean data
s2<- status[,c(3)]
tolower(iconv(s2,"ISO-8859-1","UTF-8"))
s2 <- gsub("\\d", "", s2)
s2 <- gsub("\\W", " ", s2)
s2 <- gsub("[[:punct:]]"," ", s2)
s2
s3 <-s2
enDTM <- Corpus(VectorSource(s3)) %>% TermDocumentMatrix
small3 <- read.csv("small3.csv", header = FALSE, fill=TRUE,row.names=NULL)
#readLines("smallrandomsample.csv", warn=FALSE)
#clean data
s2<- status[,c(3)]
tolower(iconv(s2,"ISO-8859-1","UTF-8"))
s2 <- gsub("\\d", "", s2)
s2 <- gsub("\\W", " ", s2)
s2 <- gsub("[[:punct:]]"," ", s2)
load("~/Desktop/FB_status copy/sentiment4.RData")
load("~/Desktop/FB_status copy/topic1.RData")
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/home/spark")
}
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sc <- sparkR.init(master = "local[*]", sparkEnvir = list(spark.driver.memory="2g"))
sc <- sparkR.init()
sqlContext <- sparkRSQL.init(sc)
library(devtools)
install_github("amplab-extras/SparkR-pkg", subdir="pkg")
git clone https://github.com/amplab-extras/SparkR-pkg.git
devtools::install_github('apache/spark@v1.4.0', subdir='R/pkg')
library(rvest)
read_html(http://www.info.gov.hk/gia/general/201409/29c.htm)
read_html("http://www.info.gov.hk/gia/general/201409/29c.htm")
plot(fitted.regression, which = 1)
plot(fitted.regression, which = 1)
fitted.regression <- lm(y ~ x)
x <- 1: 10
y <- x^2
fitted.regression <- lm(y ~ x)
plot(fitted.regression, which = 1)
geom_point()
top.1000.sites <- read.csv('data/top_1000_sites.tsv', sep = '\t', stringsAsFactors = FALSE)
set.seed(1)x <- seq(0, 1, by = 0.01)y <- sin(2 * pi * x) + rnorm(length(x), 0, 0.1)n <- length(x)indices <- sort(sample(1:n, round(0.5 * n)))training.x <- x[indices] training.y <- y[indices]test.x <- x[-indices] test.y <- y[-indices]df <- data.frame(X = x, Y = y)training.df <- data.frame(X = training.x, Y = training.y) test.df <- data.frame(X = test.x, Y = test.y)rmse <- function(y, h) {        return(sqrt(mean((y - h) ^ 2))) }
set.seed(1)
x <- seq(0, 1, by = 0.01)
y <- sin(2 * pi * x) + rnorm(length(x), 0, 0.1)
n <- length(x)
indices <- sort(sample(1:n, round(0.5 * n)))
training.x <- x[indices] training.y <- y[indices]
test.x <- x[-indices]
test.y <- y[-indices]
df <- data.frame(X = x, Y = y)
training.df <- data.frame(X = training.x, Y = training.y) test.df <- data.frame(X = test.x, Y = test.y)
training.df <- data.frame(X = training.x, Y = training.y)
test.df <- data.frame(X = test.x, Y = test.y)
training.df <- data.frame(X = training.x, Y = training.y)
training.x <- x[indices]
training.y <- y[indices]
training.df <- data.frame(X = training.x, Y = training.y)
test.df <- data.frame(X = test.x, Y = test.y)
rmse <- function(y, h) {
return(sqrt(mean((y - h) ^ 2))) }
rmse
library('glmnet')
glmnet.fit <- with(training.df, glmnet(poly(X, degree = 10), Y))
lambdas <- glmnet.fit$lambda
performance <- data.frame()for (lambda in lambdas){        performance <- rbind(performance,                             data.frame(Lambda = lambda,                                        RMSE = rmse(test.y, with(test.df, predict(glmnet.fit, poly(X,                                                                                                   degree = 10), s = lambda)))))}
performance <- data.frame()
for (lambda in lambdas)
{
performance <- rbind(performance,
data.frame(Lambda = lambda,
RMSE = rmse(test.y, with(test.df, predict(glmnet.fit, poly(X,
degree = 10), s = lambda)))))
}
performance
library(topicmodels)
library(topicmodels)
statusswl <- read.csv("user_all_status_swl.csv", header = T, fill=TRUE,row.names=NULL)
library(topicmodels)
statusswl <- read.csv("user_all_status_swl.csv", header = T, fill=TRUE,row.names=NULL)
library(topicmodels)
require(magrittr)
library(topicmodels)
install.packages("topicmodels")
library(topicmodels)
require(magrittr)
require(tm)
library(RTextTools)
install.packages("RTextTools")
library(RTextTools)
install.packages("tidyverse")
library(tidyverse)
library(stringr)
library(textcat)
install.packages("R6")
library(tidyverse)
install.packages("gtable")
install.packages("tidyverse")
